# Задание 1
## Вопрос
При построении предиктивных моделей мы используем Logreg, Random Forest и LightGBM. Пропишите достоинства и недостатки данных моделей и предложите свои. Пропишите ее плюсы и минусы при использовании.

## Ответ
Логистическая регрессия, случайный лес и LGBM - это разные типы моделей. Logreg - это линейная модель, подразумевающая линейные зависимости таргета от признаков. Случайный лес и LGBM - это ансамбли моделей, в которых различными способами 

## Logreg:
Логистическая модель дает неплохие вероятности принадлежности к классу, особенно после калибровки. Но предполагает линейные зависимости и отсутствие мультиколлинеарности, а значит нужно заранее понимать, что действительно влияет на вероятность класса и суметь, с помощью преобразований, вытащить эти линейные зависимости из правильных признаков.
Достоинства:
* Бысто обучается
* Легко интерпретируется (экспонента веса признака показывает влияние на вероятность)
Недостатки:
* Необходимость предобработки (стандартизация, кодирование категориальных признаков)
* Необходимость сложного feature engineering для "вытаскивания" линейных зависимостей

## Случайный лес:
Ансамблевый метод - bagging - в котором на разных подвыборках признаков и объектов обучаются независимые глубокие деревья, а окончательный прогноз определяется голосованием большинства. Поскольку тип модели один и тот же (дерево), то смещение получается одинаковым, а за счет усреднения (голосования большинства) уменьшается разброс. В целом, это метод нахождения сложных нелинейных зависимостей.

Достоинства:
* Относительно высокая точность из коробки
* Можно обучать на признаках почти как есть, без обработки
* Встроенная оценка важности признаков по частоте использования и степени очищения

Недостатки:
* Долго обучается

## LightGBM:
Бустинги - это ансамбль, в котором деревья обучаются последовательно на ошибках предыдущих. С каждым новым шагом вся модель усложняется, уменьшая смещение. 

Достоинства:
* Чаще самая точная модель при сравнении c моделями выше
* Быстро обучается
* Требует меньше памяти
* Встроенная поддержка категориальных признаков

Недостатки:
* Много гиперпараметров и алгоритмов обучения
* Нужно много данных


## Другие модели:
Дерево решений - больше для аналитики, чем прогнозов. Склонно к переобучению при большой глубине.
SVM - если большую важность играет сама классификация, нежели оценка вероятности. Хотя тоже можно откалибровать. Долго обучается на большом кол-ве данных, но обученная занимает мало памяти.
Нейронные сети - очень много методов. Можно искать научные статьи по теме и повторять за ними. 
